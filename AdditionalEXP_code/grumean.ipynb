{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this to install benchpots in the colab env\n",
    "# !pip install benchpots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from benchpots.datasets import preprocess_physionet2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 16:40:50 [INFO]: You're using dataset physionet_2012, please cite it properly in your work. You can find its reference information at the below link: \n",
      "https://github.com/WenjieDu/TSDB/tree/main/dataset_profiles/physionet_2012\n",
      "2024-10-25 16:40:50 [INFO]: Dataset physionet_2012 has already been downloaded. Processing directly...\n",
      "2024-10-25 16:40:50 [INFO]: Dataset physionet_2012 has already been cached. Loading from cache directly...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-25 16:40:50 [INFO]: Loaded successfully!\n",
      "2024-10-25 16:40:56 [WARNING]: rate is 0, no missing values are artificially added.\n",
      "2024-10-25 16:40:56 [INFO]: Total sample number: 3997\n",
      "2024-10-25 16:40:56 [INFO]: Training set size: 2557 (63.97%)\n",
      "2024-10-25 16:40:56 [INFO]: Validation set size: 640 (16.01%)\n",
      "2024-10-25 16:40:56 [INFO]: Test set size: 800 (20.02%)\n",
      "2024-10-25 16:40:56 [INFO]: Number of steps: 48\n",
      "2024-10-25 16:40:56 [INFO]: Number of features: 36\n",
      "2024-10-25 16:40:56 [INFO]: Train set missing rate: 79.51%\n",
      "2024-10-25 16:40:56 [INFO]: Validating set missing rate: 79.63%\n",
      "2024-10-25 16:40:56 [INFO]: Test set missing rate: 79.78%\n"
     ]
    }
   ],
   "source": [
    "features=['ALP', \n",
    "          'ALT', \n",
    "          'AST', \n",
    "          'Albumin',\n",
    "          'BUN',\n",
    "          'Bilirubin',\n",
    "          'Cholesterol',\n",
    "          'Creatinine',\n",
    "          'FiO2',\n",
    "          'GCS',\n",
    "          'Glucose',\n",
    "          'HCO3',\n",
    "          'HCT',\n",
    "          'HR', \n",
    "          'K', \n",
    "          'Lactate', \n",
    "          'Mg', \n",
    "          'Na', \n",
    "          'PaCO2', \n",
    "          'PaO2', \n",
    "          'Platelets', \n",
    "          'RespRate', \n",
    "          'SaO2', \n",
    "          'Temp', \n",
    "          'TroponinI', \n",
    "          'TroponinT', \n",
    "          'Urine', \n",
    "          'WBC', \n",
    "          'Weight', \n",
    "          'pH',\n",
    "\n",
    "          'NISysABP',\n",
    "          'SysABP',\n",
    "          'NIMAP',\n",
    "          'MAP',\n",
    "          'NIDiasABP',\n",
    "          'DiasABP',\n",
    "          ]\n",
    "data = preprocess_physionet2012('set-a', rate=0, features=features)\n",
    "\n",
    "for key in ['train_X', 'val_X', 'test_X']:\n",
    "    a, b = 35, 34\n",
    "    idx = np.array(np.isnan(data[key][:, :,a]))\n",
    "    data[key][:, :, a][idx] = data[key][:, :, b][idx]\n",
    "    a, b = 33, 32\n",
    "    idx = np.array(np.isnan(data[key][:, :,a]))\n",
    "    data[key][:, :, a][idx] = data[key][:, :, b][idx]\n",
    "    a, b = 31, 30\n",
    "    idx = np.array(np.isnan(data[key][:, :,a]))\n",
    "    data[key][:, :, a][idx] = data[key][:, :, b][idx]\n",
    "    data[key] = data[key][:, :, [u for u in range(36) if u not in [30, 32, 34]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1346265/3113696779.py:3: RuntimeWarning: Mean of empty slice\n",
      "  replace = np.nanmean(sample, axis=0)\n"
     ]
    }
   ],
   "source": [
    "for key in ['train_X', 'val_X', 'test_X']:\n",
    "    for x, sample in enumerate(data[key]):\n",
    "        replace = np.nanmean(sample, axis=0)\n",
    "        nanidx = np.isnan(replace)\n",
    "        for k, i in enumerate(replace):\n",
    "            if nanidx[k]:\n",
    "                i = 0\n",
    "            data[key][x, :, k][np.array(np.isnan(sample[:, k]))] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "class gruSimple(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_features = 33,\n",
    "        n_classes = 2,\n",
    "        rnn_hidden_size = 43,\n",
    "        num_layers = 1,\n",
    "    ):\n",
    "        super(gruSimple, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = rnn_hidden_size\n",
    "        self.gru = nn.GRU(n_features, rnn_hidden_size, num_layers, batch_first=True)\n",
    "        # Define the top regressor layer with batch normalization and dropout\n",
    "        self.fc = nn.Linear(rnn_hidden_size, n_classes)\n",
    "        self.batch_norm = nn.BatchNorm1d(n_classes)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden state with zeros\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(x.device)\n",
    "\n",
    "        # Forward propagate through GRU\n",
    "        out, _ = self.gru(x, h0)\n",
    "        # Get the last hidden state\n",
    "        last_hidden_state = out[:, -1, :]\n",
    "        out = self.fc(last_hidden_state)\n",
    "        out = self.batch_norm(out)\n",
    "        out = self.dropout(out)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "early_stopping_patience = 3  # Number of epochs to wait for improvement\n",
    "best_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training function with early stopping\n",
    "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    global best_loss, patience_counter\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for _, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(torch.nan_to_num(inputs))\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backward pass and optimize\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/10:.4f}')\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()  # Set the model to evaluation mode\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                outputs = model(torch.nan_to_num(inputs))\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        print(f'Validation Loss after Epoch [{epoch+1}/{num_epochs}]: {val_loss:.4f}')\n",
    "        \n",
    "        # Early stopping check\n",
    "        if val_loss < best_loss:\n",
    "            best_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= early_stopping_patience:\n",
    "                print(f'Early stopping at epoch {epoch+1}')\n",
    "                break\n",
    "        \n",
    "        model.train()  # Set back to training mode\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def evaluate_model(val_loader, model, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    outputs = torch.tensor([]).to(device)\n",
    "    lab = torch.tensor([]).to(device)\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            output = model(torch.nan_to_num(inputs))\n",
    "            outputs = torch.concat([outputs, output])\n",
    "            lab = torch.concat([lab, labels])\n",
    "    return outputs, lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = TensorDataset(torch.tensor(data['train_X'].astype(np.float32)), torch.tensor(data['train_y']))\n",
    "valdata = TensorDataset(torch.tensor(data['val_X'].astype(np.float32)), torch.tensor(data['val_y']))\n",
    "testdata = TensorDataset(torch.tensor(data['test_X'].astype(np.float32)), torch.tensor(data['test_y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(traindata, batch_size=64)\n",
    "val_loader = DataLoader(valdata, batch_size=64)\n",
    "test_loader = DataLoader(testdata, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gruSimple(33, 2, 64)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 2.6781\n",
      "Validation Loss after Epoch [1/50]: 0.6156\n",
      "Epoch [2/50], Loss: 2.5417\n",
      "Validation Loss after Epoch [2/50]: 0.6066\n",
      "Epoch [3/50], Loss: 2.4729\n",
      "Validation Loss after Epoch [3/50]: 0.5918\n",
      "Epoch [4/50], Loss: 2.4135\n",
      "Validation Loss after Epoch [4/50]: 0.5642\n",
      "Epoch [5/50], Loss: 2.3176\n",
      "Validation Loss after Epoch [5/50]: 0.5542\n",
      "Epoch [6/50], Loss: 2.2747\n",
      "Validation Loss after Epoch [6/50]: 0.5480\n",
      "Epoch [7/50], Loss: 2.2535\n",
      "Validation Loss after Epoch [7/50]: 0.5303\n",
      "Epoch [8/50], Loss: 2.2495\n",
      "Validation Loss after Epoch [8/50]: 0.5406\n",
      "Epoch [9/50], Loss: 2.2274\n",
      "Validation Loss after Epoch [9/50]: 0.5336\n",
      "Epoch [10/50], Loss: 2.2156\n",
      "Validation Loss after Epoch [10/50]: 0.5326\n",
      "Early stopping at epoch 10\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Train the model with early stopping\n",
    "num_epochs = 50\n",
    "train(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7718066397311683"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output, true = evaluate_model(test_loader, model, device)\n",
    "display(roc_auc_score(true.cpu(), output[:, 1].cpu()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NDE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
